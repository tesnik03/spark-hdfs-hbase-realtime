consumableEvents {

  topic {
    consumeFrom: "events"
  }

  windowDuration: 30s

  slideDuration: 10s

  spark {
    master: "local[4]"
    appName: "equipments-spark-kafka"
    executorMemory: "10G"
    coresMax: "6"
    defaultParallelism: "60"
  }

  sparkStreaming {
    batchDuration: 5s
    checkpoint: ${java.io.tmpdir}
  }

  stringCodec {
    encoding: "UTF8"
  }

  kafkaSource {
    // kafka brokers
    "metadata.broker.list": "localhost:9092"
    // start from the latest messages
    "auto.offset.reset": "largest"
  }

  kafkaSink {
    // kafka bootstrap
    "bootstrap.servers": "localhost:9092"
    // ack from leader
    "acks": "1"
    // block spark job if kafka is overloaded
    "block.on.buffer.full": "true"
    // retry forever
    //"retries": "2147483647"
    //"retry.backoff.ms": "1500"
  }

  service{
    host:"0.0.0.0"
    port:8091
  }

  hbase{
    hostname:"127.0.0.1"
    port:6000
  }

  message{
    count:10
  }

  separator{
    line:"\n"
    delimiter:"\u0001"
  }

}
